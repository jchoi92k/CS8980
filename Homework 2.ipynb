{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework 3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMxPTPS4ClTuWCV7Zbw80Wa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jchoi92k/CS8980/blob/main/Homework%202.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4dunb4cnzC4"
      },
      "source": [
        "1. Create a cosine similarity matrix for all of Shakespeare’s works found in the provided\r\n",
        "file. This will result in a 42 by 42 matrix with the cosine similarity between each of his\r\n",
        "works. In other words, calculate the document-wise cosine similarity between all of\r\n",
        "Shakepeare’s works. (50 points). Use TF_IDF for this. Note, you can use the Cosine\r\n",
        "Similarity function on scikit-learn or implement your own, but no other library/package is\r\n",
        "allowed.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZavZvb6n3dm"
      },
      "source": [
        "import numpy as np\r\n",
        "import os\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.metrics.pairwise import cosine_similarity\r\n",
        "\r\n",
        "\r\n",
        "# All files were uploaded to a folder named 'shakespeare'\r\n",
        "textpaths = [os.path.join('shakespeare', w) for w in os.listdir('shakespeare')]\r\n",
        "texts = []\r\n",
        "\r\n",
        "# Open files\r\n",
        "for textpath in textpaths:\r\n",
        "  with open(textpath, 'r', encoding='utf-8') as f:\r\n",
        "    content = f.read()\r\n",
        "    texts.append(content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4vLiMPl35SK",
        "outputId": "b702c35a-3a7b-416c-c38e-1185b14bde12"
      },
      "source": [
        "# TF-IDF vectorization\r\n",
        "vct = TfidfVectorizer()\r\n",
        "fitted = vct.fit_transform(texts)\r\n",
        "\r\n",
        "# Compute cosine similarity\r\n",
        "cosim = cosine_similarity(fitted, fitted)\r\n",
        "print(cosim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.59813572 0.65459176 ... 0.52515851 0.57395169 0.69694474]\n",
            " [0.59813572 1.         0.66801609 ... 0.5890345  0.59258345 0.71771293]\n",
            " [0.65459176 0.66801609 1.         ... 0.59895863 0.66716633 0.79038899]\n",
            " ...\n",
            " [0.52515851 0.5890345  0.59895863 ... 1.         0.52277672 0.62033426]\n",
            " [0.57395169 0.59258345 0.66716633 ... 0.52277672 1.         0.70530628]\n",
            " [0.69694474 0.71771293 0.79038899 ... 0.62033426 0.70530628 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3ZR8cyR5kmw",
        "outputId": "7ecce30f-db81-4ad4-ee5c-87981df1e254"
      },
      "source": [
        "# To show shape\r\n",
        "cosim.shape"
      ],
      "execution_count": 409,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42, 42)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 409
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKjJgLdp5r9m"
      },
      "source": [
        "2. Write a function that takes the previous matrix and a number n as parameters (nothing\r\n",
        "else will be accepted) and return the top n similar works. Use the function to output the\r\n",
        "top 10 similar works. (30 points).\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLvii13A5wEJ",
        "outputId": "998cb00f-20df-46f6-dce1-d56f31cd8bc9"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "# Takes matrix and number n as arguments and returns indices of top n similar works in descending order\r\n",
        "def topnsim(prevmat, n):\r\n",
        "  # Create dataframe with matrix to sort the cosine similarities\r\n",
        "  rows = []\r\n",
        "  cols = []\r\n",
        "  for row in range(len(prevmat)):\r\n",
        "    rows += [row] * len(prevmat)\r\n",
        "  for col in range(len(prevmat[0])):\r\n",
        "    cols.append(col)\r\n",
        "  cols = cols * len(prevmat[0])\r\n",
        "  vals = prevmat.flatten()\r\n",
        "  df = pd.DataFrame({'row_index':rows, 'col_index':cols, 'values':vals})\r\n",
        "\r\n",
        "  # Remove all 1.0 cosine-similarities and sort (descending)\r\n",
        "  df = df[df['values'] < 0.999999]\r\n",
        "  df = df.sort_values(by=['values'], ascending=False)\r\n",
        "\r\n",
        "  # Append results to this list\r\n",
        "  res = []\r\n",
        "\r\n",
        "  # Skip every other row because they are necessarily duplicates\r\n",
        "  for x, y in zip(df['row_index'][::2], df['col_index'][::2]):\r\n",
        "    if len(res) < 10:\r\n",
        "      res.append((x, y))\r\n",
        "  return res\r\n",
        "\r\n",
        "# Get indices using the function defined above\r\n",
        "indices = topnsim(cosim, 10)\r\n",
        "\r\n",
        "# Print similar works using indices\r\n",
        "filenames = os.listdir('shakespeare')\r\n",
        "for indice in indices:\r\n",
        "  print(f'\"{filenames[indice[0]]}\" is similar to \"{filenames[indice[1]]}\"')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"lucrece_TXT_FolgerShakespeare.txt\" is similar to \"venus-and-adonis_TXT_FolgerShakespeare.txt\"\n",
            "\"henry-iv-part-1_TXT_FolgerShakespeare.txt\" is similar to \"henry-iv-part-2_TXT_FolgerShakespeare.txt\"\n",
            "\"lucrece_TXT_FolgerShakespeare.txt\" is similar to \"shakespeares-sonnets_TXT_FolgerShakespeare.txt\"\n",
            "\"henry-vi-part-1_TXT_FolgerShakespeare.txt\" is similar to \"henry-vi-part-2_TXT_FolgerShakespeare.txt\"\n",
            "\"richard-iii_TXT_FolgerShakespeare.txt\" is similar to \"richard-ii_TXT_FolgerShakespeare.txt\"\n",
            "\"venus-and-adonis_TXT_FolgerShakespeare.txt\" is similar to \"shakespeares-sonnets_TXT_FolgerShakespeare.txt\"\n",
            "\"henry-v_TXT_FolgerShakespeare.txt\" is similar to \"henry-viii_TXT_FolgerShakespeare.txt\"\n",
            "\"henry-vi-part-2_TXT_FolgerShakespeare.txt\" is similar to \"henry-vi-part-3_TXT_FolgerShakespeare.txt\"\n",
            "\"henry-vi-part-2_TXT_FolgerShakespeare.txt\" is similar to \"richard-ii_TXT_FolgerShakespeare.txt\"\n",
            "\"king-john_TXT_FolgerShakespeare.txt\" is similar to \"henry-v_TXT_FolgerShakespeare.txt\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0VuxwSz7nm0"
      },
      "source": [
        "3. Using the code from the Language Models II class, train two simple language models\r\n",
        "using all of the files (together) in shakespeares-works_TXT_FolgerShakespeare.zip. One\r\n",
        "model should be trained using bigrams, the other using trigrams. (40 points)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9JrqE3F7q-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4523e8af-f307-4a04-f011-b991c42cd98d"
      },
      "source": [
        "import nltk\r\n",
        "from nltk import bigrams, trigrams, sent_tokenize, word_tokenize\r\n",
        "from collections import Counter, defaultdict\r\n",
        "\r\n",
        "nltk.download('punkt')\r\n",
        "\r\n",
        "# Tokenize sentences\r\n",
        "tokenized_texts = []\r\n",
        "\r\n",
        "for text in texts:\r\n",
        "  tokenized_sents = sent_tokenize(text)\r\n",
        "  for sent in tokenized_sents:\r\n",
        "    tokenized_words = word_tokenize(sent)\r\n",
        "    tokenized_texts.append(tokenized_words)\r\n",
        "\r\n",
        "# For a trigram model => model\r\n",
        "model = defaultdict(lambda: defaultdict(lambda: 0))\r\n",
        "\r\n",
        "for sentence in tokenized_texts:\r\n",
        "    for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\r\n",
        "        model[(w1, w2)][w3] += 1\r\n",
        " \r\n",
        "for w1_w2 in model:\r\n",
        "    total_count = float(sum(model[w1_w2].values()))\r\n",
        "    for w3 in model[w1_w2]:\r\n",
        "        model[w1_w2][w3] /= total_count\r\n",
        "\r\n",
        "# For a bigram model => model2\r\n",
        "model2 = defaultdict(lambda: defaultdict(lambda: 0))\r\n",
        "\r\n",
        "for sentence in tokenized_texts:\r\n",
        "    for w1, w2 in bigrams(sentence, pad_right=True, pad_left=True):\r\n",
        "        model2[w1][w2] += 1\r\n",
        " \r\n",
        "for w1 in model2:\r\n",
        "    total_count = float(sum(model2[w1].values()))\r\n",
        "    for w2 in model2[w1]:\r\n",
        "        model2[w1][w2] /= total_count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlOLjaIL7rUC"
      },
      "source": [
        "4. Write a function that takes the following three parameters: model, list of start words,\r\n",
        "number of sentences to generate. This function should return the sentences generated\r\n",
        "as a list. DO NOT print anything to the screen from within the function. Use this function\r\n",
        "to generate 10 sentences with the bigram model from the previous question, and 5\r\n",
        "sentences with the trigram model from the previous question. (30 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyuypfMD7y4w"
      },
      "source": [
        "import random\r\n",
        "\r\n",
        "def generate_sentence(mdl, list_of_start_word, nofsent):\r\n",
        "  # Append results here\r\n",
        "  res = []\r\n",
        "\r\n",
        "  # Find out if model is a bigram model or a trigram model\r\n",
        "  ngram_mode = ''\r\n",
        "  if type(list(mdl)[0]) == tuple:\r\n",
        "    ngram_mode = 'trigram'\r\n",
        "  else:\r\n",
        "    ngram_mode = 'bigram'\r\n",
        "\r\n",
        "  # Generate sentences\r\n",
        "  for _ in range(nofsent):\r\n",
        "    newsent = list_of_start_word.copy()\r\n",
        "    sentence_finished = False\r\n",
        "    while not sentence_finished:\r\n",
        "      # select a random probability threshold  \r\n",
        "      r = random.random()\r\n",
        "      accumulator = .0\r\n",
        "\r\n",
        "      # For trigrams\r\n",
        "      if ngram_mode == 'trigram':\r\n",
        "        for word in mdl[tuple(newsent[-2:])].keys():\r\n",
        "            accumulator += mdl[tuple(newsent[-2:])][word]\r\n",
        "            # select words that are above the probability threshold\r\n",
        "            if accumulator >= r:\r\n",
        "                newsent.append(word)\r\n",
        "                break\r\n",
        "        if newsent[-2:] == [None, None]:\r\n",
        "            sentence_finished = True\r\n",
        "\r\n",
        "      # For bigrams\r\n",
        "      elif ngram_mode == 'bigram':\r\n",
        "        for word in mdl[newsent[-1]].keys():\r\n",
        "            accumulator += mdl[newsent[-1]][word]\r\n",
        "            # select words that are above the probability threshold\r\n",
        "            if accumulator >= r:\r\n",
        "                newsent.append(word)\r\n",
        "                break\r\n",
        "        if newsent[-1:] == [None]:\r\n",
        "            sentence_finished = True\r\n",
        "\r\n",
        "    generated = ' '.join([t for t in newsent if t])\r\n",
        "    res.append(generated)\r\n",
        "    \r\n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n374BROpTXym",
        "outputId": "e315fd93-f818-4cdd-a957-aa85c9af2d9d"
      },
      "source": [
        "# 10 sentences with the bigram model\r\n",
        "random.seed(15)\r\n",
        "generate_sentence(model2, ['and'], 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"and sprinkles in faith , Deposing thee speak more exalted with his surname , To th ' offended you believe me must think you have I am king ?\",\n",
              " 'and wagered with the custard ; I attach you , And scarce serve thee .',\n",
              " 'and learn , for the highest mount .',\n",
              " \"and whose souls ; and yet a desire of Caesar 's love , Soul-killing witches that I do my falsehood with feet I am proof hath power to know One that will stir !\",\n",
              " \"and finally , He 's the bones .\",\n",
              " 'and his grave ?',\n",
              " 'and both the request a card or to obey the map .',\n",
              " 'and loving king , lieutenant .',\n",
              " 'and that there ?',\n",
              " \"and bridegroom 's shot a maid again .\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 403
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2BBnmLpI2fO",
        "outputId": "f1ee2cfd-79bb-4473-ab2c-f9708315464b"
      },
      "source": [
        "# 5 sentences with the trigram model\r\n",
        "random.seed(15)\r\n",
        "generate_sentence(model, ['and', 'the'], 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"and the King's Tavern .\",\n",
              " 'and the prisoner ?',\n",
              " \"and the greatness of his valor can not tell -- But Banquo 's safe ?\",\n",
              " 'and the blows you gave him when Hector has knocked out , Must fetch him .',\n",
              " 'and the thing he would change places with his hat ; it is no such thing , what then ?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 404
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STB4iSUq73H9"
      },
      "source": [
        "Bonus (20 points): Using the same methodology from questions 1 and 2, create a\r\n",
        "similarity matrix between the 20 newsgroups corpus. And find the top 5 similar\r\n",
        "newsgroups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMjH2RKLCgBn"
      },
      "source": [
        "import numpy as np\r\n",
        "import os\r\n",
        "from sklearn.datasets import fetch_20newsgroups\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.metrics.pairwise import cosine_similarity\r\n",
        "\r\n",
        "# Fetch data\r\n",
        "data = fetch_20newsgroups()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-_tFTfKDhRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd7e23ec-0ec0-44af-9beb-a2f2563dedfc"
      },
      "source": [
        "# Create empty dictionary to sort different newsgroup categories\r\n",
        "emdic = defaultdict(str)\r\n",
        "\r\n",
        "for w, k in zip(data.data, data.target):\r\n",
        "  emdic[k] = emdic[k] + \"\\n\" + w\r\n",
        "newstexts = []\r\n",
        "\r\n",
        "for key in sorted(emdic.keys()):\r\n",
        "  newstexts.append(emdic[key])\r\n",
        "\r\n",
        "# TF-IDF vectorization\r\n",
        "vct_n = TfidfVectorizer()\r\n",
        "fitted_n = vct.fit_transform(newstexts)\r\n",
        "\r\n",
        "# Compute cosine similarity\r\n",
        "cosim_n = cosine_similarity(fitted_n, fitted_n)\r\n",
        "print(cosim_n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.9094271  0.05523086 0.88417914 0.90353323 0.89906611\n",
            "  0.77552111 0.93001747 0.9058185  0.90239171 0.8587065  0.92177557\n",
            "  0.93163157 0.94660545 0.91830139 0.97013249 0.9449579  0.91569666\n",
            "  0.95436217 0.97017371]\n",
            " [0.9094271  1.         0.05796562 0.91413931 0.92825112 0.92834378\n",
            "  0.85646081 0.92462808 0.90894411 0.89050075 0.85412391 0.91324122\n",
            "  0.94087947 0.93113063 0.92194395 0.90809985 0.91542406 0.88169114\n",
            "  0.91564806 0.91395076]\n",
            " [0.05523086 0.05796562 1.         0.05744383 0.05733129 0.056494\n",
            "  0.05259049 0.05673589 0.05597304 0.05472295 0.05218132 0.05595068\n",
            "  0.05774222 0.05614403 0.05536226 0.05484025 0.05619588 0.05269622\n",
            "  0.0554367  0.05510923]\n",
            " [0.88417914 0.91413931 0.05744383 1.         0.94475744 0.90136798\n",
            "  0.83384539 0.91845189 0.90008117 0.87931077 0.84843403 0.89333141\n",
            "  0.92985151 0.89963781 0.89441629 0.88508149 0.89747512 0.86216335\n",
            "  0.89789488 0.89203503]\n",
            " [0.90353323 0.92825112 0.05733129 0.94475744 1.         0.91681064\n",
            "  0.84018088 0.93800781 0.91800563 0.90618302 0.87453687 0.91148553\n",
            "  0.94973616 0.91775354 0.91803887 0.90597957 0.92015601 0.88683032\n",
            "  0.92037839 0.91319644]\n",
            " [0.89906611 0.92834378 0.056494   0.90136798 0.91681064 1.\n",
            "  0.79994049 0.91755398 0.90059815 0.88178581 0.85827839 0.91754311\n",
            "  0.93564213 0.91254113 0.91476297 0.90454687 0.91582002 0.88368549\n",
            "  0.91623345 0.90947328]\n",
            " [0.77552111 0.85646081 0.05259049 0.83384539 0.84018088 0.79994049\n",
            "  1.         0.82514962 0.81468802 0.8015134  0.76086253 0.7800954\n",
            "  0.8378872  0.81679456 0.80282895 0.76767517 0.79014955 0.74915685\n",
            "  0.78101904 0.78059132]\n",
            " [0.93001747 0.92462808 0.05673589 0.91845189 0.93800781 0.91755398\n",
            "  0.82514962 1.         0.94946181 0.92787545 0.89494836 0.92496904\n",
            "  0.95812525 0.93909016 0.93645511 0.93224206 0.95014205 0.91984223\n",
            "  0.95016205 0.94302036]\n",
            " [0.9058185  0.90894411 0.05597304 0.90008117 0.91800563 0.90059815\n",
            "  0.81468802 0.94946181 1.         0.90700199 0.87629504 0.90361102\n",
            "  0.93747957 0.91999468 0.9165013  0.90805495 0.92761719 0.89806989\n",
            "  0.92806425 0.92105906]\n",
            " [0.90239171 0.89050075 0.05472295 0.87931077 0.90618302 0.88178581\n",
            "  0.8015134  0.92787545 0.90700199 1.         0.91165632 0.89375268\n",
            "  0.91986121 0.91252369 0.91372698 0.9129369  0.92336558 0.90095844\n",
            "  0.92455809 0.91917596]\n",
            " [0.8587065  0.85412391 0.05218132 0.84843403 0.87453687 0.85827839\n",
            "  0.76086253 0.89494836 0.87629504 0.91165632 1.         0.86956409\n",
            "  0.89022063 0.8709508  0.89075578 0.87842409 0.89579976 0.88216737\n",
            "  0.89616637 0.88565169]\n",
            " [0.92177557 0.91324122 0.05595068 0.89333141 0.91148553 0.91754311\n",
            "  0.7800954  0.92496904 0.90361102 0.89375268 0.86956409 1.\n",
            "  0.93769609 0.92962961 0.93042164 0.9326808  0.94205516 0.91379508\n",
            "  0.94518971 0.9369282 ]\n",
            " [0.93163157 0.94087947 0.05774222 0.92985151 0.94973616 0.93564213\n",
            "  0.8378872  0.95812525 0.93747957 0.91986121 0.89022063 0.93769609\n",
            "  1.         0.94255411 0.94258766 0.93377525 0.94805672 0.91251174\n",
            "  0.94770172 0.94062567]\n",
            " [0.94660545 0.93113063 0.05614403 0.89963781 0.91775354 0.91254113\n",
            "  0.81679456 0.93909016 0.91999468 0.91252369 0.8709508  0.92962961\n",
            "  0.94255411 1.         0.9371115  0.95029278 0.94768811 0.92102577\n",
            "  0.95073708 0.95352479]\n",
            " [0.91830139 0.92194395 0.05536226 0.89441629 0.91803887 0.91476297\n",
            "  0.80282895 0.93645511 0.9165013  0.91372698 0.89075578 0.93042164\n",
            "  0.94258766 0.9371115  1.         0.9320355  0.94550285 0.92611841\n",
            "  0.94631504 0.93853191]\n",
            " [0.97013249 0.90809985 0.05484025 0.88508149 0.90597957 0.90454687\n",
            "  0.76767517 0.93224206 0.90805495 0.9129369  0.87842409 0.9326808\n",
            "  0.93377525 0.95029278 0.9320355  1.         0.95511889 0.93810033\n",
            "  0.96628356 0.98294207]\n",
            " [0.9449579  0.91542406 0.05619588 0.89747512 0.92015601 0.91582002\n",
            "  0.79014955 0.95014205 0.92761719 0.92336558 0.89579976 0.94205516\n",
            "  0.94805672 0.94768811 0.94550285 0.95511889 1.         0.94655583\n",
            "  0.97077727 0.96466528]\n",
            " [0.91569666 0.88169114 0.05269622 0.86216335 0.88683032 0.88368549\n",
            "  0.74915685 0.91984223 0.89806989 0.90095844 0.88216737 0.91379508\n",
            "  0.91251174 0.92102577 0.92611841 0.93810033 0.94655583 1.\n",
            "  0.94805638 0.946396  ]\n",
            " [0.95436217 0.91564806 0.0554367  0.89789488 0.92037839 0.91623345\n",
            "  0.78101904 0.95016205 0.92806425 0.92455809 0.89616637 0.94518971\n",
            "  0.94770172 0.95073708 0.94631504 0.96628356 0.97077727 0.94805638\n",
            "  1.         0.96989198]\n",
            " [0.97017371 0.91395076 0.05510923 0.89203503 0.91319644 0.90947328\n",
            "  0.78059132 0.94302036 0.92105906 0.91917596 0.88565169 0.9369282\n",
            "  0.94062567 0.95352479 0.93853191 0.98294207 0.96466528 0.946396\n",
            "  0.96989198 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fo5Rvg_WNlL7",
        "outputId": "5253035b-b0f6-4888-a755-98f8ac321efc"
      },
      "source": [
        "# Get indices using the function defined above\r\n",
        "indices_n = topnsim(cosim_n, 5)\r\n",
        "\r\n",
        "# Print similar works using indices\r\n",
        "for indice in indices_n:\r\n",
        "  print(f'\"{data.target_names[indice[0]]}\" is similar to \"{data.target_names[indice[1]]}\"')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"soc.religion.christian\" is similar to \"talk.religion.misc\"\n",
            "\"talk.politics.guns\" is similar to \"talk.politics.misc\"\n",
            "\"talk.religion.misc\" is similar to \"alt.atheism\"\n",
            "\"alt.atheism\" is similar to \"soc.religion.christian\"\n",
            "\"talk.religion.misc\" is similar to \"talk.politics.misc\"\n",
            "\"talk.politics.misc\" is similar to \"soc.religion.christian\"\n",
            "\"talk.politics.guns\" is similar to \"talk.religion.misc\"\n",
            "\"rec.autos\" is similar to \"sci.electronics\"\n",
            "\"soc.religion.christian\" is similar to \"talk.politics.guns\"\n",
            "\"talk.politics.misc\" is similar to \"alt.atheism\"\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}